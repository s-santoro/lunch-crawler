{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------POS--------\n",
      "['aktuell', 'all', 'angebo', 'back', 'bitt', 'bra', 'ch', 'dess', 'dienstag', 'donnerstag', 'fisch', 'fleisch', 'freitag', 'fri', 'frisch', 'gru', 'hausgemach', 'hom', 'impressum', 'kas', 'klei', 'knoblauch', 'kontak', 'menu', 'misch', 'mittagsmenu', 'montag', 'mus', 'offnungszei', 'pomm', 'poul', 'prei', 'priceentity', 'reis', 'reservatio', 'restaura', 'rich', 'rindfleisch', 'sala', 'samstag', 'sauc', 'schloss', 'servier', 'sonntag', 'supp', 'toma', 'vegetarisch', 'vorspei', 'zurich', 'zwiebel']\n",
      "---------NEG--------\n",
      "['aktuell', 'all', 'anfahr', 'anfrag', 'angebo', 'anlass', 'bankett', 'bitt', 'ch', 'datenschutz', 'de', 'ess', 'find', 'fr', 'freitag', 'freu', 'gas', 'ger', 'hom', 'hotel', 'impressum', 'job', 'konn', 'kontak', 'kuch', 'link', 'mail', 'menu', 'montag', 'nich', 'niess', 'off', 'offnungszei', 'perso', 'priceentity', 'reservatio', 'reservier', 'restaura', 'samstag', 'schloss', 'schweiz', 'sonntag', 'speisekar', 'stell', 'tag', 'team', 'telefo', 'wein', 'weinkar', 'werd']\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from luigi.contrib.spark import PySparkTask\n",
    "from luigi.parameter import IntParameter, DateSecondParameter\n",
    "from luigi import LocalTarget, Task, WrapperTask\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem.cistem import Cistem\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%run Importer.ipynb\n",
    "\n",
    "\n",
    "class Preprocessor(Task):\n",
    "# External Methods for preprocessing\n",
    "    def toLowerCase(self, text):\n",
    "        return text.lower()\n",
    "    \n",
    "    def priceTagger(self, text):\n",
    "        # match patterns with decimalpoint or comma, real rappen-values and chf,sfr,fr or .-:\n",
    "        # whitespaces inside () are optional\n",
    "        # characters inside [] are prohibited\n",
    "        # x => number\n",
    "        # a => letter\n",
    "        #   [x or a or , or .]xxx.xx( )chf[x or a]\n",
    "        text = re.sub(r'[^0-9a-z\\.\\,][0-9]{1,3}(\\.|\\,)[0-9](5|0) {0,1}(chf|sfr|fr|\\.\\-)[^0-9a-z]', ' priceentity ', text)\n",
    "        # match following patterns with chf,sfr,fr or .-:\n",
    "        # characters inside () are optional\n",
    "        # characters inside [] are prohibited\n",
    "        # x => number\n",
    "        # a => letter\n",
    "        #   [x or a or , or .]xxx( )chf[x or a]\n",
    "        text = re.sub(r'[^0-9a-z\\.\\,][0-9]{1,3} {0,1}(chf|sfr|fr|\\.\\-)[^0-9a-z]', ' priceentity ', text)\n",
    "        # match following patterns with decimalpoint or comma, real rappen-values and chf,sfr,fr or .-:\n",
    "        # characters inside () are optional\n",
    "        # characters inside [] are prohibited\n",
    "        # x => number\n",
    "        # a => letter\n",
    "        #   [x or a or , or .]chf(.)( )xxx.xx[x or a]\n",
    "        text = re.sub(r'[^0-9a-z\\.\\,](chf|sfr|fr)\\.{0,1} {0,1}[0-9]{1,3}(\\.|\\,)[0-9](5|0)[^0-9a-z]', ' priceentity ', text)\n",
    "        # match following patterns with decimalpoint or comma and real rappen-values:\n",
    "        # characters inside () are optional\n",
    "        # characters inside [] are prohibited\n",
    "        # x => number\n",
    "        # a => letter\n",
    "        #   [x or a or , or .]xxx.xx[x or a]\n",
    "        # to avoid detecting day times or dates the regex only detects\n",
    "        # prices with values after decimalpoint over 59 (i.e 12.60 or 1.65)\n",
    "        #text = re.sub(r'[^0-9a-z\\.\\,][0-9]{1,3}(\\.|\\,)[6-9](0|5)[^0-9\\.a-z]', ' priceentity ', text)\n",
    "        return text\n",
    "        \n",
    "    def removeSpecialCharacters(self, text):\n",
    "        return re.sub(r'[^éàèÉÀÈäöüÄÖÜa-zA-Z]+', ' ', str(text)) #0-9 entfernt\n",
    "    \n",
    "    def removeSingleCharacters(self, text):\n",
    "        return re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    \n",
    "    def removeMultiSpaces(self, text):\n",
    "        return re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    \n",
    "    def stemText(self, text):\n",
    "        stemmer = Cistem()\n",
    "        return [stemmer.stem(word) for word in text.split()]\n",
    "    \n",
    "    def removeStopWords(self, words):\n",
    "        # use own stopword list\n",
    "        stop = pd.read_csv('../stopwords_no_umlaute.txt', header=None)\n",
    "        stop.columns = ['word']\n",
    "        # convert list to set for word comparison\n",
    "        stopwordSet = set(stop.word)\n",
    "        wordsFiltered = []\n",
    "        wordsRemoved = []\n",
    "        for w in words:\n",
    "            if w not in stopwordSet:\n",
    "                wordsFiltered.append(w)\n",
    "            if w in stopwordSet:\n",
    "                wordsRemoved.append(w)\n",
    "\n",
    "        #print(\"Removed words: %s\" % wordsRemoved)\n",
    "        #print(\"Percentage of removed words: %s\" % (len(wordsRemoved)/len(words)*100))\n",
    "        return wordsFiltered\n",
    "    \n",
    "    def replaceUmlaut(self, text):\n",
    "        text = re.sub(r'ä', 'a', text)\n",
    "        text = re.sub(r'ö', 'o', text)\n",
    "        text = re.sub(r'ü', 'u', text)\n",
    "        return text\n",
    "        \n",
    "    \n",
    "    # Date for Output-File prefix\n",
    "    from datetime import date, timedelta\n",
    "    date = DateSecondParameter(default=datetime.datetime.now())\n",
    "    \n",
    "    # Method to declare the Output-File\n",
    "    def output(self):\n",
    "        prefix = self.date.strftime(\"%Y-%m-%dT%H%M%S\")\n",
    "        return LocalTarget(\"../data/%s_FrequentWordFinder_out.csv\" % prefix, format=UTF8)\n",
    "    \n",
    "    # Method to define the required Task (Importer)\n",
    "    def requires(self):\n",
    "        return Importer()\n",
    "\n",
    "\n",
    "    # Preprocess the imported Data\n",
    "    def run(self):\n",
    "        df = pd.read_csv(self.input().path)\n",
    "        output_df = pd.DataFrame(columns=('text', 'url', 'title', 'Class'))\n",
    "        \n",
    "        # Preprocessing\n",
    "        for index, document in df.iterrows():\n",
    "            # Text Preprocessing\n",
    "            text = self.toLowerCase(str(document.text))\n",
    "            text = self.priceTagger(text)\n",
    "            text = self.removeSpecialCharacters(text)\n",
    "            text = self.removeSingleCharacters(text)\n",
    "            text = self.removeMultiSpaces(text)\n",
    "            text = self.stemText(text)\n",
    "            #text = text.split(' ')  #--> Nur Anwenden, falls Stemming weggelassen wird\n",
    "            text = self.removeStopWords(text)\n",
    "            \n",
    "            # Title Preprocessing\n",
    "            title = self.toLowerCase(str(document.title))\n",
    "            title = self.replaceUmlaut(title)\n",
    "            title = self.removeSpecialCharacters(title)\n",
    "            title = self.removeSingleCharacters(title)\n",
    "            title = self.removeMultiSpaces(title)\n",
    "            \n",
    "            #Write rows for Output-File\n",
    "            row = [text, document.url, title, document.Class]\n",
    "            output_df.loc[index] = row\n",
    "        \n",
    "        \n",
    "        # Bag of Words\n",
    "        # max = Amount of Words\n",
    "        # binary: Anzahl Wörter im Dokument irrelevant\n",
    "        pos_vectorizer = CountVectorizer(max_features=50, binary=True) #, min_df=5, max_df=0.7  \n",
    "        neg_vectorizer = CountVectorizer(max_features=50, binary=True) #, min_df=5, max_df=0.7  \n",
    "\n",
    "        pos_bow=pd.DataFrame(columns=('text', 'url', 'title', 'Class'))\n",
    "        neg_bow=pd.DataFrame(columns=('text', 'url', 'title', 'Class')) \n",
    "        for index, document in output_df.iterrows():\n",
    "            row = [document.text, document.url, document.title, document.Class]\n",
    "            if document.Class == 1:\n",
    "                pos_bow.loc[index] = row\n",
    "                pos_bow.text[index] = ' '.join(pos_bow.text[index])\n",
    "            else:\n",
    "                neg_bow.loc[index] = row\n",
    "                neg_bow.text[index] = ' '.join(neg_bow.text[index])\n",
    "        \n",
    "        np.set_printoptions(threshold=np.inf) # Ganzes Array printen\n",
    "        pos = pos_vectorizer.fit_transform(pos_bow.text).toarray()\n",
    "        print('---------POS--------')\n",
    "        print(pos_vectorizer.get_feature_names())\n",
    "        #print(pos)\n",
    "        neg = neg_vectorizer.fit_transform(neg_bow.text).toarray() \n",
    "        print('---------NEG--------')\n",
    "        print(neg_vectorizer.get_feature_names())\n",
    "        #print(neg)\n",
    "        \n",
    "        \n",
    "        # Write .csv-File\n",
    "        with self.output().open(\"w\") as out:\n",
    "            output_df.to_csv(out, encoding=\"utf-8\")\n",
    "            \n",
    "    \n",
    " \n",
    "\n",
    "pre = Preprocessor()\n",
    "pre.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['back', 'bra', 'dess', 'dienstag', 'donnerstag', 'fisch', 'fleisch', 'fri', 'frisch', 'gru', 'hausgemach', 'kas', 'klei', 'knoblauch', 'misch', 'mittagsmenu', 'mus', 'pomm', 'poul', 'prei', 'reis', 'rich', 'rindfleisch', 'sala', 'sauc', 'servier', 'supp', 'toma', 'vegetarisch', 'vorspei', 'zurich', 'zwiebel']\n",
      "['anfahr', 'anfrag', 'anlass', 'bankett', 'datenschutz', 'de', 'ess', 'find', 'fr', 'freu', 'gas', 'ger', 'hotel', 'job', 'konn', 'kuch', 'link', 'mail', 'nich', 'niess', 'off', 'perso', 'reservier', 'schweiz', 'speisekar', 'stell', 'tag', 'team', 'telefo', 'wein', 'weinkar', 'werd']\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "poswords = ['aktuell', 'all', 'angebo', 'back', 'bitt', 'bra', 'ch', 'dess', 'dienstag', 'donnerstag', 'fisch', 'fleisch', 'freitag', 'fri', 'frisch', 'gru', 'hausgemach', 'hom', 'impressum', 'kas', 'klei', 'knoblauch', 'kontak', 'menu', 'misch', 'mittagsmenu', 'montag', 'mus', 'offnungszei', 'pomm', 'poul', 'prei', 'priceentity', 'reis', 'reservatio', 'restaura', 'rich', 'rindfleisch', 'sala', 'samstag', 'sauc', 'schloss', 'servier', 'sonntag', 'supp', 'toma', 'vegetarisch', 'vorspei', 'zurich', 'zwiebel']\n",
    "negwords = ['aktuell', 'all', 'anfahr', 'anfrag', 'angebo', 'anlass', 'bankett', 'bitt', 'ch', 'datenschutz', 'de', 'ess', 'find', 'fr', 'freitag', 'freu', 'gas', 'ger', 'hom', 'hotel', 'impressum', 'job', 'konn', 'kontak', 'kuch', 'link', 'mail', 'menu', 'montag', 'nich', 'niess', 'off', 'offnungszei', 'perso', 'priceentity', 'reservatio', 'reservier', 'restaura', 'samstag', 'schloss', 'schweiz', 'sonntag', 'speisekar', 'stell', 'tag', 'team', 'telefo', 'wein', 'weinkar', 'werd']\n",
    "\n",
    "for i in range(len(poswords)):\n",
    "    for j in range(len(negwords)):\n",
    "        if poswords[i] == negwords[j]:\n",
    "            poswords[i] = 'remove'\n",
    "            negwords[j] = 'remove'\n",
    "\n",
    "while 'remove' in poswords: poswords.remove('remove')\n",
    "while 'remove' in negwords: negwords.remove('remove')\n",
    "    \n",
    "\n",
    "print(poswords)\n",
    "print(negwords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
